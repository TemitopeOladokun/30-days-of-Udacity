# 30-days-of-Udacity

## Day 1 : 26/09/2019
1. I took the pledge #30daysofUdacity in my Deep Learning Nanodegree.
![](https://github.com/TemitopeOladokun/30-days-of-Udacity/blob/master/Screenshot%20(244).png)
2. Completed Lesson 1 on deep learning nanodegree class.
3. Revisited mlcourses.ai lesson on DEcision Trees and Random Forest.
https://www.youtube.com/watch?v=H4XlBTPv5rQ&feature=youtu.be
4. Watched Siraj Raval video on Decision Forest and Random Forest for clarity
https://www.youtube.com/watch?v=QHOazyP-YlM

## WHAT I LEARNT
* The collection of Decision Tree is Random Forest
* Random Forest used for both Classification and Regression problem
* Random Forest is good for small dataset.
* Broadened my knowledge on Matrix multiplication and Matrix dot product
* Decision tree is prone to error and it is instable



## Day 2 : 27/09/2019
1. I started Introduction to Neural Networks
2. Broadened my knowledge on Perceptron    https://deepai.org/machine-learning-glossary-and-terms/perceptron
3. Watched a video on step function    https://www.youtube.com/watch?v=tHwpj9b4zZo

### WHAT I LEARNT
* The heart of deep learning is Neural Network 
* Neural networks have nodes, edges, layers
* Perceptron is an algorithm for binary classifier. It consist of foru main parts : Inptu values, Weights and biases, net sum and an activation function
* Another name for Perception is Linear Binary Classifier
* Default equation:
                    ##Equation = Wx + Bias
                    W = Weights
                    x = Values
                    B = Bias 



## Day 3 : 28/09/2019
1. Read about the cost function equation
2. I learnt categories of model in Data Science
3. Different between local and global minimum   https://statinfer.com/204-5-10-local-vs-global-minimum/


### WHAT I LEARNT
* The co-efficient of a bias is 1
* If the question is to determine probability of a dataset. Use Predictive Model
* If the question is to show relationship of a dataset. Use Descriptive Model
* If the question requires Yes or No answer of a dataset. Use Classification Model
* Matrix is a rectangular array of numbers. Mathematically : Matrix = M x N
* Vector is a N x 1 matrix


## Day 4: 29/09/2019
1. Lesson 1:12 - Non- Linear Region
2. Lesson 1:13 - Error Function
3. Lesson 1:14 - Softmax
4. Broadened my knowledge about softmax   https://developers.google.com/machine-learning/crash-course/multi-class-neural-networks/softmax

### WHAT I LEARNT
* Error function is used to detect how close we are to the goal
* Error function must be differentiable
* Error function must be continuous bot discrete
* Predictions are answers gotten from Algorithm
* Converting step function to discrete is by using another activation function called Sigmoid function
* Softmax is another word for normalization of numbers
* To be proficint in AI, you need to be proficient in Object Oriented Programming


## Day 5: 30/09/2019
1. Completed Lesson 1
2. Started Lesson 2
3. Explicit video of One-Hot Encoding  https://www.youtube.com/watch?v=v_4KWmkwmsU 
4. Watched this video image classifier https://www.youtube.com/watch?v=cAICT4Al5Ow




## Day 6: 01/10/2019
1. Completed Lesson 2 - Implementing Gradient Descent
2. Started and Completed Lesson 3 - Training neural networks


                        
## Day 7: 02/10/2019
1. Trying to Style Trasnfer my picture but not working. Trying to fix the error
2. Started Lesson 4 
3. Read a little about style Transfer


## DAY 8: 03/10/2019
1.	Completed all subtopics in Lesson 2 - Neural Networks 
2.	Viewed my first project â€“ Predicting Bike share pattern


### WHAT I LEARNT
* Difference between Underfitting and Overfitting
* What is Regularization? 
* L1 and L2 Regularization
* Dropout is the solution to Overfitting
* Random Restart is use to solve the problem of local minimum
* Other Activation function aside Sigmoid. They are Hyperbolic Tangent Function and Rectified Linear Unit (RELU) Function


## DAY 9: 04/10/2019
1. Working on my project - Predicting Bike-sharing Patterns
2. Trying to style transfer my images with the fast style transfer code 
3. Reading about how to build neural network with pytorch  
https://www.datahubbs.com/deep-learning-101-first-neural-network-with-pytorch/?fbclid=IwAR2_MxZ6aAgWKunezBjgCPn4mIE_tpflWLFZ0yMv-kBDsTD8KpwGlqRrYyU


### WHAT I LEARNT
* It is very interesting when you see the concepts of the class been implemented with codes.
* Learnt Forwardfeed Propagation and Back Propagation
* How to tune hyperparameters : Learning rate, number of iteractions et cetera


## DAY 10: 05/10/2019
1. Working on my project - Predicting Bike-sharing Patterns
2. Learning how to use Github professionally. Using https://www.udacity.com material 
3. Built multivariable using Linear regression


## DAY 11: 06/10/2019
1. Working on my project - Predicting Bike-sharing Patterns
2. Started Sentiment analysis videos


## DAY 12: 07/10/2019

1. Submitted my first project on Predicting Bike-sharing Patterns
2. Continued lessons on Sentiment analysis


## DAY 13:  08/10/2019
1.  I continued my course on sentiment analysis
2. Dived into some documentation in Python     https://docs.python.org/2/library/collections.html


## DAY 14: 09/10/2019
1. Solving the projects in Sentiment analysis videos
2. Studying some python documentation


## DAY 15: 10/10/2019
1. Solving the projects in Sentiment analysis videos


## DAY 16: 11/10/2019
1. Watched some videos on Neural Network
2. Read some medium article


## DAY 17: 12/10/2019
1. Attended a meetup where Linear regression and logistic regression were discussed
2. Learnt about the difference in their equations
3. Read some articles on neural network
4. I discovered there are some similarities between AI and Robotics

### WHAT I LEARNT
* I discovered that if linear equation is been used for logistic regression, it makes it difficult to identify the local minimum.


## DAY 18: 13/10/2019
1. Revisiting Bayes Rule in Introduction to Machine Learning Udacity's video
2. Read article about it   https://towardsdatascience.com/what-is-bayes-rule-bb6598d8a2fd


## DAY 19:14/10/2019
1. It is all about Algebraic mathematics
2. Worked on some Python code

### WHAT I LEARNT
* Impossibility is a Mirage - Brace up
* Brushin up on Python Object Oriented Programming


## DAY 20: 15/10/2019
1. Learning Algebraic concept. Thank you Udacity for an awesome material
2. Revisiting sentiment analysis
3. This article is enlightening    https://medium.com/dsnet/chai-time-data-science-show-announcement-bfaaf38df219
Tomorrow is another day for a good progress

### WHAT I LEARNT
* There is nothing as good has learning the basis
* Avoid assumptions


## DAY 21: 16/10/2019
1. Sorted out the error in my sentiment analysis code
2. Rounding up the lesson and moving on to Introduction to Deep Learning with Pytorch


## DAY 22: 17/10/2019
1. Going through Introduction to Deep Learning with Pytorch
2. Read about fully connected network  https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html



## DAY 23:18/10/2019
1. Watching Introduction to Deep Learning with Pytorch videos
2. Going through the codes too


## DAY 24: 19/10/2019
1. Revised Sentiment analysis project


## DAY 25: 20/10/2019
1. Revising Backpropagation and also reading some articles


## DAY 26: 21/10/2019
1. Learning the basis has been an amazing experience - Essential mathematics topics in AI
2. Read some articles about AI and Deep Learning



## DAY 27: 22/10/2019
1. Clarified my doubt on Linear regression and logistic regression
https://ml-cheatsheet.readthedocs.io/en/latest/logistic_regression.html
2. Revising Introduction to deep learning with Pytorch
3. Watched a video about element-wise operation https://www.youtube.com/watch?v=2GPZlRVhQWY

### WHAT I LEARNT
* I also discovered that DREAMS are VALID but HARD-WORK AUTHENTICATE it.
* ![](https://github.com/TemitopeOladokun/30-days-of-Udacity/blob/master/Screenshot%20(296).png)
* ![](https://github.com/TemitopeOladokun/30-days-of-Udacity/blob/master/Screenshot%20(297).png)


## DAY 28: 23/10/2019
1. Solving Project 4 in Sentiment analysis
2. Solved Network Architecture with Pytorch


## DAY 29: 24/10/2019
1. Watched transfer learning videos
2. Solved some mathematics question
3. Read some articles about CNN
4. Read some articles about RNN


## DAY 30: 25/10/2019
1. Started Convolutional Neural Network
2. Attended the Webinar by Sourena Yadegari (My Mentor)


## DAY 31: 26/10/2019
1. Continued with my CNN Videos
2. Read some CNN articles


## DAY 32: 27/10/2019
1. Read an article on MLP, CNN and its application with Pytorch


## DAT 33: 28/10/2019
1. Started the video on MLPs vs CNN
2. Learnt about Filters and Convolutional layer
3. Filters and Egdes
4. Frequency in Images as regards CNN

### WHAT I LEARNT
* MLPs convert images to Tensor while CNN convert to matrix
* CNN gropus in edges
